#!/usr/bin/env python3
"""
RAG Unified API Endpoint - API duy nh·∫•t cho t·∫•t c·∫£ query/response
"""

from fastapi import APIRouter, HTTPException, Query, Depends
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
import logging
import torch
from sqlalchemy.orm import Session

from app.services.rag_service_unified import get_rag_service_unified
from app.services.chat_service_unified import get_chat_service_unified
from app.core.database import get_db

logger = logging.getLogger(__name__)

router = APIRouter()

# Pydantic Models
class UnifiedQueryRequest(BaseModel):
    """Request model cho unified query API"""
    question: str = Field(..., description="C√¢u h·ªèi c·∫ßn tr·∫£ l·ªùi", min_length=1, max_length=1000)
    top_k: Optional[int] = Field(default=5, description="S·ªë l∆∞·ª£ng ngu·ªìn t√†i li·ªáu t·ªëi ƒëa", ge=1, le=20)
    filter_category: Optional[str] = Field(default=None, description="L·ªçc theo danh m·ª•c: 'luat', 'english', 'vietnamese', 'all'")
    include_sources: Optional[bool] = Field(default=True, description="C√≥ bao g·ªìm th√¥ng tin ngu·ªìn t√†i li·ªáu kh√¥ng")
    similarity_threshold: Optional[float] = Field(default=None, description="Ng∆∞·ª°ng ƒë·ªô t∆∞∆°ng ƒë·ªìng t·ªëi thi·ªÉu", ge=0.0, le=1.0)

class SourceInfo(BaseModel):
    """Th√¥ng tin ngu·ªìn t√†i li·ªáu"""
    filename: str
    display_name: str
    category: str
    content_preview: str
    similarity_score: float
    content_length: int

class UnifiedQueryResponse(BaseModel):
    """Response model cho unified query API"""
    question: str
    answer: str
    sources: List[SourceInfo]
    total_sources: int
    confidence: float = Field(..., description="ƒê·ªô tin c·∫≠y c·ªßa c√¢u tr·∫£ l·ªùi (0-1)")
    method: str = Field(..., description="Ph∆∞∆°ng ph√°p t·∫°o c√¢u tr·∫£ l·ªùi")
    processing_time_ms: int
    filter_category: str
    timestamp: str
    service_version: str

class ServiceStats(BaseModel):
    """Th·ªëng k√™ service"""
    service_name: str
    version: str
    status: str
    total_documents: int
    total_chunks: int
    categories: Dict[str, Any]
    device: str
    default_settings: Dict[str, Any]

# Chat-related models
class ChatRequest(BaseModel):
    """Request cho chat v·ªõi l·ªãch s·ª≠"""
    message: str = Field(..., description="Tin nh·∫Øn ng∆∞·ªùi d√πng", min_length=1, max_length=2000)
    chat_id: Optional[int] = Field(None, description="ID cu·ªôc tr√≤ chuy·ªán hi·ªán t·∫°i")
    user_id: Optional[int] = Field(None, description="ID ng∆∞·ªùi d√πng")
    session_id: Optional[str] = Field(None, description="ID phi√™n tr√≤ chuy·ªán")
    top_k: Optional[int] = Field(default=5, description="S·ªë l∆∞·ª£ng ngu·ªìn t√†i li·ªáu", ge=1, le=20)
    filter_category: Optional[str] = Field(default=None, description="L·ªçc theo danh m·ª•c")
    rag_settings: Optional[Dict[str, Any]] = Field(default=None, description="C·∫•u h√¨nh RAG t√πy ch·ªânh")

class ChatResponse(BaseModel):
    """Response cho chat"""
    message_id: int
    chat_id: int
    user_message: str
    ai_response: str
    sources: List[SourceInfo]
    total_sources: int
    confidence: float
    processing_time_ms: int
    timestamp: str

class ChatHistoryResponse(BaseModel):
    """Response cho l·ªãch s·ª≠ chat"""
    chats: List[Dict[str, Any]]
    total: int
    page: int
    per_page: int
    filters: Dict[str, Any]

class ChatMessagesResponse(BaseModel):
    """Response cho tin nh·∫Øn chat"""
    messages: List[Dict[str, Any]]
    total: int
    page: int
    per_page: int

class ChatAnalyticsResponse(BaseModel):
    """Response cho analytics chat"""
    chat_id: int
    chat_info: Dict[str, Any]
    performance_metrics: Dict[str, Any]
    sources_analysis: Dict[str, Any]
    timeline: List[Dict[str, Any]]

@router.post("/query", response_model=UnifiedQueryResponse, 
             summary="Query RAG Unified", 
             description="API duy nh·∫•t ƒë·ªÉ h·ªèi ƒë√°p v·ªõi to√†n b·ªô t√†i li·ªáu ƒë√£ embedding")
async def unified_query(request: UnifiedQueryRequest):
    """
    **API Th·ªëng nh·∫•t cho Query/Response RAG**
    
    ƒê√¢y l√† API duy nh·∫•t ƒë·ªÉ:
    - G·ª≠i c√¢u h·ªèi v√† nh·∫≠n c√¢u tr·∫£ l·ªùi t·ª´ to√†n b·ªô knowledge base
    - T√¨m ki·∫øm trong t·∫•t c·∫£ t√†i li·ªáu ƒë√£ ƒë∆∞·ª£c embedding
    - L·ªçc theo danh m·ª•c t√†i li·ªáu
    - ƒêi·ªÅu ch·ªânh ƒë·ªô ch√≠nh x√°c v√† s·ªë l∆∞·ª£ng ngu·ªìn
    
    **Categories:**
    - `luat`: T√†i li·ªáu lu·∫≠t ph√°p Vi·ªát Nam
    - `english`: T√†i li·ªáu ti·∫øng Anh (NIST, ISO)
    - `vietnamese`: T√†i li·ªáu ti·∫øng Vi·ªát
    - `all` ho·∫∑c `null`: T·∫•t c·∫£ t√†i li·ªáu
    
    **V√≠ d·ª• c√¢u h·ªèi:**
    - "An to√†n th√¥ng tin l√† g√¨?"
    - "Lu·∫≠t An to√†n th√¥ng tin quy ƒë·ªãnh g√¨?"
    - "ISO 27001 c√≥ nh·ªØng y√™u c·∫ßu n√†o?"
    - "C√°c bi·ªán ph√°p b·∫£o m·∫≠t c∆° b·∫£n?"
    """
    try:
        logger.info(f"üìù Unified query: {request.question[:100]}...")
        
        # Get RAG service
        rag_service = await get_rag_service_unified()
        
        # Process query
        result = await rag_service.query(
            question=request.question,
            top_k=request.top_k,
            filter_category=request.filter_category,
            include_sources=request.include_sources,
            similarity_threshold=request.similarity_threshold
        )
        
        # Convert to response model
        sources = [SourceInfo(**source) for source in result.get('sources', [])]
        
        response = UnifiedQueryResponse(
            question=result['question'],
            answer=result['answer'],
            sources=sources,
            total_sources=result['total_sources'],
            confidence=result.get('confidence', 0.0),
            method=result.get('method', 'unified'),
            processing_time_ms=result.get('processing_time_ms', 0),
            filter_category=result.get('filter_category', 'all'),
            timestamp=result.get('timestamp', ''),
            service_version=result.get('service_version', '1.0.0')
        )
        
        logger.info(f"‚úÖ Query processed: {response.total_sources} sources, {response.processing_time_ms}ms")
        return response
        
    except ValueError as e:
        logger.error(f"‚ùå Validation error: {e}")
        raise HTTPException(status_code=400, detail=f"L·ªói d·ªØ li·ªáu ƒë·∫ßu v√†o: {str(e)}")
    except Exception as e:
        logger.error(f"‚ùå Unified query error: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói x·ª≠ l√Ω c√¢u h·ªèi: {str(e)}")

@router.get("/stats", response_model=ServiceStats,
            summary="Service Statistics",
            description="L·∫•y th·ªëng k√™ chi ti·∫øt v·ªÅ RAG service")
async def get_service_stats():
    """
    **Th·ªëng k√™ RAG Service**
    
    Tr·∫£ v·ªÅ th√¥ng tin chi ti·∫øt v·ªÅ:
    - S·ªë l∆∞·ª£ng t√†i li·ªáu v√† chunks
    - Ph√¢n b·ªë theo danh m·ª•c
    - C·∫•u h√¨nh m·∫∑c ƒë·ªãnh
    - Tr·∫°ng th√°i service
    """
    try:
        rag_service = await get_rag_service_unified()
        stats = await rag_service.get_service_stats()
        
        return ServiceStats(
            service_name=stats['service_name'],
            version=stats['version'],
            status=stats['status'],
            total_documents=stats['total_documents'],
            total_chunks=stats['total_chunks'],
            categories=stats['categories'],
            device=stats['device'],
            default_settings=stats['default_settings']
        )
        
    except Exception as e:
        logger.error(f"‚ùå Stats error: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói l·∫•y th·ªëng k√™: {str(e)}")

@router.get("/health",
            summary="Health Check",
            description="Ki·ªÉm tra tr·∫°ng th√°i s·ª©c kh·ªèe c·ªßa RAG service")
async def health_check():
    """
    **Health Check**
    
    Ki·ªÉm tra:
    - Service c√≥ s·∫µn s√†ng kh√¥ng
    - Th·ªùi gian kh·ªüi t·∫°o
    - Th√¥ng tin c∆° b·∫£n
    """
    try:
        rag_service = await get_rag_service_unified()
        stats = await rag_service.get_service_stats()
        
        return {
            "status": "healthy",
            "service": "RAG Unified",
            "version": "1.0.0",
            "ready": stats.get('status') == 'ready',
            "total_documents": stats.get('total_documents', 0),
            "total_chunks": stats.get('total_chunks', 0),
            "initialization_time": stats.get('initialization_time', 0)
        }
        
    except Exception as e:
        logger.error(f"‚ùå Health check error: {e}")
        return {
            "status": "unhealthy",
            "service": "RAG Unified",
            "version": "1.0.0",
            "error": str(e)
        }

@router.get("/categories",
            summary="Available Categories",
            description="L·∫•y danh s√°ch c√°c danh m·ª•c t√†i li·ªáu c√≥ s·∫µn")
async def get_categories():
    """
    **Danh m·ª•c t√†i li·ªáu c√≥ s·∫µn**
    
    Tr·∫£ v·ªÅ danh s√°ch c√°c category c√≥ th·ªÉ s·ª≠ d·ª•ng ƒë·ªÉ filter
    """
    try:
        rag_service = await get_rag_service_unified()
        stats = await rag_service.get_service_stats()
        
        categories = []
        for cat_id, cat_info in stats.get('categories', {}).items():
            categories.append({
                'id': cat_id,
                'name': {
                    'luat': 'Lu·∫≠t ph√°p Vi·ªát Nam',
                    'english': 'T√†i li·ªáu ti·∫øng Anh',
                    'vietnamese': 'T√†i li·ªáu ti·∫øng Vi·ªát'
                }.get(cat_id, cat_id.title()),
                'chunks': cat_info.get('chunks', 0),
                'total_length': cat_info.get('total_length', 0)
            })
        
        return {
            'categories': categories,
            'total_categories': len(categories),
            'note': 'S·ª≠ d·ª•ng filter_category="all" ƒë·ªÉ t√¨m trong t·∫•t c·∫£ danh m·ª•c'
        }
        
    except Exception as e:
        logger.error(f"‚ùå Categories error: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói l·∫•y danh m·ª•c: {str(e)}")

# Compatibility endpoints (deprecated)
@router.post("/query/simple", 
             deprecated=True,
             summary="[DEPRECATED] Simple Query",
             description="S·ª≠ d·ª•ng /query thay th·∫ø")
async def simple_query_deprecated(question: str = Query(..., description="C√¢u h·ªèi")):
    """Endpoint t∆∞∆°ng th√≠ch ng∆∞·ª£c - khuy·∫øn ngh·ªã s·ª≠ d·ª•ng /query"""
    request = UnifiedQueryRequest(question=question)
    return await unified_query(request)

@router.get("/info",
            summary="Service Information", 
            description="Th√¥ng tin t·ªïng quan v·ªÅ RAG Unified API")
async def service_info():
    """
    **Th√¥ng tin RAG Unified API**
    
    API duy nh·∫•t ƒë·ªÉ truy v·∫•n to√†n b·ªô knowledge base
    """
    return {
        "name": "RAG Unified API",
        "version": "1.0.0",
        "description": "API th·ªëng nh·∫•t cho query/response t·ª´ to√†n b·ªô t√†i li·ªáu ƒë√£ embedding",
        "main_endpoint": "/api/v1/rag/query",
        "features": [
            "T√¨m ki·∫øm th√¥ng minh v·ªõi embedding vectors",
            "L·ªçc theo danh m·ª•c t√†i li·ªáu", 
            "ƒêi·ªÅu ch·ªânh ƒë·ªô ch√≠nh x√°c v√† s·ªë l∆∞·ª£ng k·∫øt qu·∫£",
            "Tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi chi ti·∫øt v·ªõi ngu·ªìn tham kh·∫£o",
            "Th·ªëng k√™ v√† monitoring"
        ],
        "supported_categories": ["luat", "english", "vietnamese", "all"],
        "example_questions": [
            "An to√†n th√¥ng tin l√† g√¨?",
            "Lu·∫≠t An to√†n th√¥ng tin quy ƒë·ªãnh g√¨?", 
            "ISO 27001 c√≥ nh·ªØng y√™u c·∫ßu n√†o?",
            "C√°c bi·ªán ph√°p b·∫£o m·∫≠t c∆° b·∫£n?"
        ]
    }

# ===== CHAT HISTORY ENDPOINTS =====

@router.post("/chat", response_model=ChatResponse,
             summary="Chat v·ªõi l·ªãch s·ª≠", 
             description="G·ª≠i tin nh·∫Øn v√† l∆∞u l·ªãch s·ª≠ tr√≤ chuy·ªán")
async def chat_with_history(request: ChatRequest, db: Session = Depends(get_db)):
    """
    **Chat v·ªõi l∆∞u l·ªãch s·ª≠ tr√≤ chuy·ªán**
    
    T√≠nh nƒÉng:
    - G·ª≠i tin nh·∫Øn v√† nh·∫≠n ph·∫£n h·ªìi t·ª´ RAG
    - T·ª± ƒë·ªông l∆∞u l·ªãch s·ª≠ tr√≤ chuy·ªán
    - Theo d√µi sources v√† confidence
    - H·ªó tr·ª£ session management
    
    **Workflow:**
    1. T·∫°o chat m·ªõi ho·∫∑c s·ª≠ d·ª•ng chat hi·ªán c√≥
    2. L∆∞u tin nh·∫Øn ng∆∞·ªùi d√πng
    3. G·ªçi RAG service ƒë·ªÉ t·∫°o ph·∫£n h·ªìi
    4. L∆∞u tin nh·∫Øn AI v·ªõi metadata ƒë·∫ßy ƒë·ªß
    5. Tr·∫£ v·ªÅ k·∫øt qu·∫£ v·ªõi th√¥ng tin chat
    """
    try:
        chat_service = get_chat_service_unified(db)
        
        # X√°c ƒë·ªãnh ho·∫∑c t·∫°o chat
        if request.chat_id:
            chat_context = chat_service.get_chat_with_context(request.chat_id)
            if not chat_context:
                raise HTTPException(status_code=404, detail=f"Chat {request.chat_id} kh√¥ng t·ªìn t·∫°i")
        else:
            # T·∫°o chat m·ªõi
            title = request.message[:50] + "..." if len(request.message) > 50 else request.message
            chat = chat_service.create_chat_with_rag_context(
                title=title,
                user_id=request.user_id,
                category_filter=request.filter_category,
                session_id=request.session_id,
                rag_settings=request.rag_settings
            )
            request.chat_id = chat.id
        
        # G·ª≠i tin nh·∫Øn v√† nh·∫≠n ph·∫£n h·ªìi
        result = await chat_service.send_message_with_rag(
            chat_id=request.chat_id,
            user_message=request.message,
            user_id=request.user_id,
            override_settings=request.rag_settings
        )
        
        # Chu·∫©n b·ªã response
        sources = [SourceInfo(**source) for source in result["rag_response"].get("sources", [])]
        
        return ChatResponse(
            message_id=result["ai_message"].id,
            chat_id=request.chat_id,
            user_message=request.message,
            ai_response=result["rag_response"]["answer"],
            sources=sources,
            total_sources=result["rag_response"]["total_sources"],
            confidence=result["rag_response"].get("confidence", 0.0),
            processing_time_ms=result["rag_response"].get("processing_time_ms", 0),
            timestamp=result["rag_response"].get("timestamp", "")
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Chat error: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói chat: {str(e)}")

@router.get("/chats", response_model=ChatHistoryResponse,
            summary="L·∫•y l·ªãch s·ª≠ chat",
            description="L·∫•y danh s√°ch c√°c cu·ªôc tr√≤ chuy·ªán v·ªõi th·ªëng k√™")
async def get_chat_history(
    page: int = Query(default=1, ge=1, description="S·ªë trang"),
    per_page: int = Query(default=10, ge=1, le=100, description="S·ªë item per trang"),
    user_id: Optional[int] = Query(default=None, description="ID ng∆∞·ªùi d√πng"),
    category_filter: Optional[str] = Query(default=None, description="L·ªçc theo danh m·ª•c"),
    db: Session = Depends(get_db)
):
    """
    **L·∫•y l·ªãch s·ª≠ tr√≤ chuy·ªán**
    
    Tr·∫£ v·ªÅ:
    - Danh s√°ch c√°c cu·ªôc tr√≤ chuy·ªán
    - Th·ªëng k√™ tin nh·∫Øn, sources, confidence
    - Th√¥ng tin ph√¢n trang
    - B·ªô l·ªçc ƒë√£ √°p d·ª•ng
    """
    try:
        chat_service = get_chat_service_unified(db)
        result = chat_service.get_chats_with_stats(
            user_id=user_id,
            page=page,
            per_page=per_page,
            category_filter=category_filter
        )
        
        return ChatHistoryResponse(
            chats=result["chats"],
            total=result["total"],
            page=result["page"],
            per_page=result["per_page"],
            filters=result["filters"]
        )
        
    except Exception as e:
        logger.error(f"‚ùå Get chat history error: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói l·∫•y l·ªãch s·ª≠: {str(e)}")

@router.get("/chats/{chat_id}/messages", response_model=ChatMessagesResponse,
            summary="L·∫•y tin nh·∫Øn trong chat",
            description="L·∫•y danh s√°ch tin nh·∫Øn trong m·ªôt cu·ªôc tr√≤ chuy·ªán")
async def get_chat_messages(
    chat_id: int,
    page: int = Query(default=1, ge=1, description="S·ªë trang"),
    per_page: int = Query(default=50, ge=1, le=100, description="S·ªë item per trang"),
    db: Session = Depends(get_db)
):
    """
    **L·∫•y tin nh·∫Øn trong chat**
    
    Tr·∫£ v·ªÅ:
    - Danh s√°ch tin nh·∫Øn v·ªõi ƒë·∫ßy ƒë·ªß metadata
    - Th√¥ng tin sources cho tin nh·∫Øn AI
    - Performance metrics
    - Ph√¢n trang
    """
    try:
        chat_service = get_chat_service_unified(db)
        
        # Ki·ªÉm tra chat t·ªìn t·∫°i
        chat_context = chat_service.get_chat_with_context(chat_id)
        if not chat_context:
            raise HTTPException(status_code=404, detail=f"Chat {chat_id} kh√¥ng t·ªìn t·∫°i")
        
        result = chat_service.get_chat_messages_with_sources(
            chat_id=chat_id,
            page=page,
            per_page=per_page
        )
        
        return ChatMessagesResponse(
            messages=result["messages"],
            total=result["total"],
            page=result["page"],
            per_page=result["per_page"]
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Get chat messages error: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói l·∫•y tin nh·∫Øn: {str(e)}")

@router.get("/chats/{chat_id}/analytics", response_model=ChatAnalyticsResponse,
            summary="Analytics cho chat",
            description="L·∫•y th·ªëng k√™ chi ti·∫øt v√† ph√¢n t√≠ch cho m·ªôt cu·ªôc tr√≤ chuy·ªán")
async def get_chat_analytics(chat_id: int, db: Session = Depends(get_db)):
    """
    **Analytics chi ti·∫øt cho chat**
    
    Ph√¢n t√≠ch:
    - Performance metrics (confidence, processing time)
    - Sources analysis (t·∫ßn su·∫•t s·ª≠ d·ª•ng, ƒëi·ªÉm s·ªë)
    - Timeline c·ªßa cu·ªôc tr√≤ chuy·ªán
    - Th·ªëng k√™ t·ªïng quan
    """
    try:
        chat_service = get_chat_service_unified(db)
        result = chat_service.get_chat_analytics(chat_id)
        
        if "error" in result:
            if result["error"] == "Chat kh√¥ng t·ªìn t·∫°i":
                raise HTTPException(status_code=404, detail="Chat kh√¥ng t·ªìn t·∫°i")
            else:
                raise HTTPException(status_code=500, detail=result["error"])
        
        return ChatAnalyticsResponse(
            chat_id=result["chat_id"],
            chat_info=result["chat_info"],
            performance_metrics=result["performance_metrics"],
            sources_analysis=result["sources_analysis"],
            timeline=result["timeline"]
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Get chat analytics error: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói analytics: {str(e)}")

@router.delete("/chats/{chat_id}",
               summary="X√≥a chat",
               description="X√≥a m·ªôt cu·ªôc tr√≤ chuy·ªán (soft delete)")
async def delete_chat(chat_id: int, db: Session = Depends(get_db)):
    """
    **X√≥a cu·ªôc tr√≤ chuy·ªán**
    
    - Soft delete: chat v·∫´n t·ªìn t·∫°i trong DB nh∆∞ng b·ªã ƒë√°nh d·∫•u x√≥a
    - T·∫•t c·∫£ tin nh·∫Øn c≈©ng b·ªã ·∫©n
    - Kh√¥ng th·ªÉ kh√¥i ph·ª•c qua API
    """
    try:
        chat_service = get_chat_service_unified(db)
        
        # S·ª≠ d·ª•ng method t·ª´ parent class
        success = chat_service.delete_chat(chat_id)
        
        if not success:
            raise HTTPException(status_code=404, detail=f"Chat {chat_id} kh√¥ng t·ªìn t·∫°i")
        
        return {"message": f"ƒê√£ x√≥a chat {chat_id}", "success": True}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Delete chat error: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói x√≥a chat: {str(e)}")

@router.put("/chats/{chat_id}",
            summary="C·∫≠p nh·∫≠t chat",
            description="C·∫≠p nh·∫≠t th√¥ng tin cu·ªôc tr√≤ chuy·ªán")
async def update_chat(
    chat_id: int,
    title: Optional[str] = Query(default=None, description="Ti√™u ƒë·ªÅ m·ªõi"),
    is_active: Optional[bool] = Query(default=None, description="Tr·∫°ng th√°i ho·∫°t ƒë·ªông"),
    db: Session = Depends(get_db)
):
    """
    **C·∫≠p nh·∫≠t cu·ªôc tr√≤ chuy·ªán**
    
    C√≥ th·ªÉ c·∫≠p nh·∫≠t:
    - Ti√™u ƒë·ªÅ chat
    - Tr·∫°ng th√°i ho·∫°t ƒë·ªông
    - Metadata (trong t∆∞∆°ng lai)
    """
    try:
        chat_service = get_chat_service_unified(db)
        
        # Chu·∫©n b·ªã data c·∫≠p nh·∫≠t
        update_data = {}
        if title is not None:
            update_data["title"] = title
        if is_active is not None:
            update_data["is_active"] = is_active
        
        if not update_data:
            raise HTTPException(status_code=400, detail="Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ c·∫≠p nh·∫≠t")
        
        # S·ª≠ d·ª•ng method t·ª´ parent class
        updated_chat = chat_service.update_chat(chat_id, **update_data)
        
        if not updated_chat:
            raise HTTPException(status_code=404, detail=f"Chat {chat_id} kh√¥ng t·ªìn t·∫°i")
        
        return {
            "message": f"ƒê√£ c·∫≠p nh·∫≠t chat {chat_id}",
            "chat": {
                "id": updated_chat.id,
                "title": updated_chat.title,
                "is_active": updated_chat.is_active,
                "updated_at": updated_chat.updated_at.isoformat()
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Update chat error: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói c·∫≠p nh·∫≠t chat: {str(e)}")

# ===== FILES MANAGEMENT =====

@router.get("/files/uploaded",
            summary="L·∫•y danh s√°ch files ƒë√£ upload",
            description="L·∫•y danh s√°ch c√°c file trong th∆∞ m·ª•c documents/upload")
async def get_uploaded_files():
    """
    **L·∫•y danh s√°ch files ƒë√£ upload**
    
    Tr·∫£ v·ªÅ danh s√°ch c√°c file trong th∆∞ m·ª•c upload
    ƒë·ªÉ hi·ªÉn th·ªã trong sidebar ho·∫∑c file manager
    """
    try:
        import os
        
        upload_dir = "documents/upload"
        
        # Ki·ªÉm tra th∆∞ m·ª•c c√≥ t·ªìn t·∫°i kh√¥ng
        if not os.path.exists(upload_dir):
            return {
                "files": [],
                "total": 0,
                "message": "Th∆∞ m·ª•c upload ch∆∞a t·ªìn t·∫°i"
            }
        
        # L·∫•y danh s√°ch file trong th∆∞ m·ª•c
        files = []
        for filename in os.listdir(upload_dir):
            file_path = os.path.join(upload_dir, filename)
            if os.path.isfile(file_path):
                # L·∫•y th√¥ng tin file
                stat = os.stat(file_path)
                files.append({
                    "filename": filename,
                    "size": stat.st_size,
                    "modified": stat.st_mtime,
                    "extension": filename.split('.')[-1].lower() if '.' in filename else ''
                })
        
        # S·∫Øp x·∫øp theo th·ªùi gian modified
        files.sort(key=lambda x: x['modified'], reverse=True)
        
        return {
            "files": files,
            "total": len(files),
            "upload_dir": upload_dir
        }
        
    except Exception as e:
        logger.error(f"L·ªói khi l·∫•y danh s√°ch file upload: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói l·∫•y files: {str(e)}")

# ===== DEBUG & ADMIN ENDPOINTS =====

@router.post("/debug/reload-llm",
             summary="Reload LLM Service",
             description="Force reload LLM service for debugging")
async def reload_llm_service():
    """
    **Force Reload LLM Service**
    
    Debug endpoint ƒë·ªÉ reload LLM service
    Useful khi LLM kh√¥ng ho·∫°t ƒë·ªông
    """
    try:
        from app.services.rag_service_unified import _rag_service_unified
        
        if _rag_service_unified:
            # Reset LLM service
            _rag_service_unified.llm_service = None
            _rag_service_unified.use_llm_generation = True
            
            # Reinitialize
            await _rag_service_unified.initialize()
            
            # Check status
            llm_status = "available" if _rag_service_unified.llm_service else "not_available"
            
            return {
                "message": "LLM service reload attempted",
                "llm_status": llm_status,
                "use_llm_generation": _rag_service_unified.use_llm_generation
            }
        else:
            return {
                "message": "RAG service not initialized yet",
                "llm_status": "unknown"
            }
            
    except Exception as e:
        logger.error(f"‚ùå Reload LLM error: {e}")
        return {
            "message": f"Reload failed: {str(e)}",
            "llm_status": "error"
        }

@router.get("/debug/llm-status",
            summary="Check LLM Status",
            description="Ki·ªÉm tra tr·∫°ng th√°i LLM service")
async def check_llm_status():
    """
    **Check LLM Service Status**
    
    Debug endpoint ƒë·ªÉ ki·ªÉm tra:
    - LLM service c√≥ ƒë∆∞·ª£c load kh√¥ng
    - Memory usage
    - Configuration
    """
    try:
        from app.services.rag_service_unified import _rag_service_unified
        
        if not _rag_service_unified:
            return {
                "status": "rag_service_not_initialized",
                "llm_available": False
            }
        
        # Check LLM service
        llm_available = _rag_service_unified.llm_service is not None
        use_llm = _rag_service_unified.use_llm_generation
        
        # GPU info
        gpu_info = {}
        if torch.cuda.is_available():
            device = torch.cuda.current_device()
            total_memory = torch.cuda.get_device_properties(device).total_memory / 1024**3
            allocated_memory = torch.cuda.memory_allocated(device) / 1024**3
            
            gpu_info = {
                "gpu_name": torch.cuda.get_device_name(device),
                "total_memory_gb": round(total_memory, 2),
                "allocated_memory_gb": round(allocated_memory, 2),
                "free_memory_gb": round(total_memory - allocated_memory, 2)
            }
        
        return {
            "status": "initialized",
            "llm_available": llm_available,
            "use_llm_generation": use_llm,
            "gpu_info": gpu_info,
            "model_path": "D:/Vian/MODELS/vinallama-2.7b-chat"
        }
        
    except Exception as e:
        logger.error(f"‚ùå LLM status check error: {e}")
        return {
            "status": "error",
            "error": str(e)
        }
