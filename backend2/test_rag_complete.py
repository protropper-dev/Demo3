#!/usr/bin/env python3
"""
Test RAG hoÃ n chá»‰nh vá»›i dá»¯ liá»‡u embedding Ä‘Ã£ cÃ³
"""

import sys
import os
from pathlib import Path

# ThÃªm thÆ° má»¥c hiá»‡n táº¡i vÃ o Python path
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

def test_rag_without_llm():
    """Test RAG pipeline mÃ  khÃ´ng cáº§n load LLM"""
    print("ğŸ§ª Test RAG Pipeline (khÃ´ng cáº§n LLM)")
    print("=" * 50)
    
    try:
        import faiss
        import pickle
        import numpy as np
        from sentence_transformers import SentenceTransformer
        import settings
        
        # 1. Load FAISS index
        print("ğŸ“¥ Loading FAISS index...")
        faiss_index = faiss.read_index(str(settings.FAISS_PATH))
        print(f"âœ… FAISS Index: {faiss_index.ntotal} vectors, {faiss_index.d} dimensions")
        
        # 2. Load embedding data
        print("ğŸ“¥ Loading embedding data...")
        with open(settings.PICKLE_PATH, "rb") as f:
            data = pickle.load(f)
        print(f"âœ… Embedding Data: {len(data)} documents")
        
        # 3. Táº¡o chunks list
        all_chunks = []
        for item in data:
            if isinstance(item, dict) and "chunks" in item:
                all_chunks.extend(item["chunks"])
        print(f"âœ… Total chunks: {len(all_chunks)}")
        
        # 4. Load embedding model
        print("ğŸ“¥ Loading embedding model...")
        embedding_model = SentenceTransformer(str(settings.EMBEDDING_MODEL_FOLDER))
        print("âœ… Embedding model loaded")
        
        # 5. Test RAG pipeline
        print("\nğŸ” Testing RAG Pipeline...")
        
        test_queries = [
            "an toÃ n thÃ´ng tin",
            "luáº­t an toÃ n thÃ´ng tin Viá»‡t Nam", 
            "ISO 27001",
            "phishing attack",
            "ransomware"
        ]
        
        for query in test_queries:
            print(f"\nâ“ Query: '{query}'")
            
            # Encode query
            query_vector = embedding_model.encode([query])
            
            # Search trong FAISS
            D, I = faiss_index.search(query_vector.astype('float32'), 3)
            
            print(f"   ğŸ“Š Found {len(I[0])} relevant chunks:")
            
            # Hiá»ƒn thá»‹ chunks tÃ¬m Ä‘Æ°á»£c
            for i, idx in enumerate(I[0]):
                if idx < len(all_chunks):
                    chunk = all_chunks[idx]
                    preview = chunk[:150] + "..." if len(chunk) > 150 else chunk
                    print(f"   {i+1}. Distance: {D[0][i]:.2f}")
                    print(f"      {preview}")
                    print()
        
        return True
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False

def test_chat_utils():
    """Test utils.chat functions"""
    print("\nğŸ§ª Test Chat Utils")
    print("=" * 30)
    
    try:
        from utils.chat import load_embedding_and_chunks, get_relevant_chunks, build_prompt
        
        # Load data
        print("ğŸ“¥ Loading embedding and chunks...")
        faiss_index, chunks = load_embedding_and_chunks()
        
        if faiss_index is None:
            print("âŒ Cannot load FAISS index")
            return False
        
        if len(chunks) == 0:
            print("âŒ No chunks found")
            return False
        
        print(f"âœ… Loaded {len(chunks)} chunks")
        
        # Test get_relevant_chunks (khÃ´ng cáº§n LLM)
        test_query = "an toÃ n thÃ´ng tin"
        print(f"\nğŸ” Testing get_relevant_chunks with: '{test_query}'")
        
        # Mock embedding model Ä‘á»ƒ test
        import numpy as np
        from sentence_transformers import SentenceTransformer
        import settings
        
        embedding_model = SentenceTransformer(str(settings.EMBEDDING_MODEL_FOLDER))
        
        # Táº¡o function mock
        def mock_get_relevant_chunks(query, faiss_index, chunks, top_k=3):
            query_vector = embedding_model.encode([query])
            D, I = faiss_index.search(query_vector.astype('float32'), top_k)
            
            context_chunks = []
            for i in I[0]:
                if i < len(chunks):
                    chunk = chunks[i]
                    context_chunks.append(chunk.strip())
            
            return context_chunks
        
        relevant_chunks = mock_get_relevant_chunks(test_query, faiss_index, chunks)
        print(f"âœ… Found {len(relevant_chunks)} relevant chunks")
        
        # Test build_prompt
        prompt = build_prompt(relevant_chunks, test_query)
        print(f"âœ… Built prompt (length: {len(prompt)} chars)")
        print(f"   Prompt preview: {prompt[:200]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False

def main():
    """Cháº¡y táº¥t cáº£ tests"""
    print("ğŸš€ Backend2 Complete RAG Test")
    print("=" * 60)
    
    success1 = test_rag_without_llm()
    success2 = test_chat_utils()
    
    print(f"\n{'='*60}")
    print("ğŸ“Š Test Results:")
    print(f"RAG Pipeline Test: {'âœ… PASS' if success1 else 'âŒ FAIL'}")
    print(f"Chat Utils Test: {'âœ… PASS' if success2 else 'âŒ FAIL'}")
    
    if success1 and success2:
        print("\nğŸ‰ All RAG tests passed!")
        print("âœ… Backend2 RAG pipeline is ready!")
        print("ğŸ’¡ You can now start the server and test chat functionality")
        return True
    else:
        print("\nâš ï¸  Some tests failed")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
